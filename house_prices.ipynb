{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "house_prices.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "huxG_oBA34r-",
        "colab_type": "text"
      },
      "source": [
        "# Kaggle House Prices Challenge"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KiqpRYLO34sK",
        "colab_type": "text"
      },
      "source": [
        "## House Prices: Advanced Regression Techniques\n",
        "\n",
        "Predict sales prices and practice feature engineering, RFs, and gradient boosting\n",
        "\n",
        "(Link: https://www.kaggle.com/c/house-prices-advanced-regression-techniques/overview)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KbeIohHI34sP",
        "colab_type": "text"
      },
      "source": [
        "First, we start by importing the libraries needed for this project."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EE7j5m2V34sU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lzn8XJfI34sl",
        "colab_type": "text"
      },
      "source": [
        "Loading the data into dataframes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvcujN4i34sp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test = pd.read_csv(\"test.csv\")\n",
        "train = pd.read_csv(\"train.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ul4E9Oes34s2",
        "colab_type": "code",
        "outputId": "c22a437b-d970-4dd2-c37a-0240231d8ec3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "test.shape, train.shape"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1459, 80), (1460, 81))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "z_y1O_xB34tQ",
        "colab_type": "code",
        "outputId": "08510cff-bcd5-4bc6-e44c-44b39faacde9",
        "colab": {}
      },
      "source": [
        "test.columns, train.columns"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Index(['Id', 'MSSubClass', 'MSZoning', 'LotFrontage', 'LotArea', 'Street',\n",
              "        'Alley', 'LotShape', 'LandContour', 'Utilities', 'LotConfig',\n",
              "        'LandSlope', 'Neighborhood', 'Condition1', 'Condition2', 'BldgType',\n",
              "        'HouseStyle', 'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd',\n",
              "        'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType',\n",
              "        'MasVnrArea', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual',\n",
              "        'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinSF1',\n",
              "        'BsmtFinType2', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'Heating',\n",
              "        'HeatingQC', 'CentralAir', 'Electrical', '1stFlrSF', '2ndFlrSF',\n",
              "        'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath',\n",
              "        'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'KitchenQual',\n",
              "        'TotRmsAbvGrd', 'Functional', 'Fireplaces', 'FireplaceQu', 'GarageType',\n",
              "        'GarageYrBlt', 'GarageFinish', 'GarageCars', 'GarageArea', 'GarageQual',\n",
              "        'GarageCond', 'PavedDrive', 'WoodDeckSF', 'OpenPorchSF',\n",
              "        'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'PoolQC',\n",
              "        'Fence', 'MiscFeature', 'MiscVal', 'MoSold', 'YrSold', 'SaleType',\n",
              "        'SaleCondition'],\n",
              "       dtype='object'),\n",
              " Index(['Id', 'MSSubClass', 'MSZoning', 'LotFrontage', 'LotArea', 'Street',\n",
              "        'Alley', 'LotShape', 'LandContour', 'Utilities', 'LotConfig',\n",
              "        'LandSlope', 'Neighborhood', 'Condition1', 'Condition2', 'BldgType',\n",
              "        'HouseStyle', 'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd',\n",
              "        'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType',\n",
              "        'MasVnrArea', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual',\n",
              "        'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinSF1',\n",
              "        'BsmtFinType2', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'Heating',\n",
              "        'HeatingQC', 'CentralAir', 'Electrical', '1stFlrSF', '2ndFlrSF',\n",
              "        'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath',\n",
              "        'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'KitchenQual',\n",
              "        'TotRmsAbvGrd', 'Functional', 'Fireplaces', 'FireplaceQu', 'GarageType',\n",
              "        'GarageYrBlt', 'GarageFinish', 'GarageCars', 'GarageArea', 'GarageQual',\n",
              "        'GarageCond', 'PavedDrive', 'WoodDeckSF', 'OpenPorchSF',\n",
              "        'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'PoolQC',\n",
              "        'Fence', 'MiscFeature', 'MiscVal', 'MoSold', 'YrSold', 'SaleType',\n",
              "        'SaleCondition', 'SalePrice'],\n",
              "       dtype='object'))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W1XPWi4Q34ti",
        "colab_type": "text"
      },
      "source": [
        "We can see that the test dataset contains one more variable compared to the train dataset - which is the \"SalePrice\" variable. In our analysis / prediction this serves as the dependent variable we want to predict given the houses' characteristics."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "-a5jWlw734tm",
        "colab_type": "code",
        "outputId": "bbef1fa5-1286-40ce-845d-3f8e5161e1a4",
        "colab": {}
      },
      "source": [
        "train.SalePrice.describe()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count      1460.000000\n",
              "mean     180921.195890\n",
              "std       79442.502883\n",
              "min       34900.000000\n",
              "25%      129975.000000\n",
              "50%      163000.000000\n",
              "75%      214000.000000\n",
              "max      755000.000000\n",
              "Name: SalePrice, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "twuT-h6w34t5",
        "colab_type": "text"
      },
      "source": [
        "## Data preprocessing and cleaning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CDLUxnqE34t-",
        "colab_type": "text"
      },
      "source": [
        "We'll start the Data Cleaning by checking if the dependent variable in the test dataset contains any missing values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "fGZym2UE34uC",
        "colab_type": "code",
        "outputId": "30c4662a-ae1f-473a-f13a-44b1872032e4",
        "colab": {}
      },
      "source": [
        "train.SalePrice.isnull().sum()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vlniKhP_34uW",
        "colab_type": "text"
      },
      "source": [
        "All observations contain data for the target variable, therefore we can continue by taking a look at all the other variables contained in the train and test dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "usqO58Df34ua",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "miss_count_train = train.isnull().sum().sort_values(ascending=False)\n",
        "perc_miss_train = (train.isnull().sum()/train.isnull().count()).sort_values(ascending=False)\n",
        "missings_train = pd.concat([miss_count_train, perc_miss_train], axis=1, keys=[\"Total\", \"Percent\"])\n",
        "\n",
        "miss_count_test = test.isnull().sum().sort_values(ascending=False)\n",
        "perc_miss_test = (test.isnull().sum() / test.isnull().count()).sort_values(ascending=False)\n",
        "missings_test = pd.concat([miss_count_test, perc_miss_test], axis=1, keys=[\"Total\", \"Percent\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "NiPA3qGA34up",
        "colab_type": "code",
        "outputId": "ea3a3d6f-6e92-4e79-f1e2-f688e06f0a25",
        "colab": {}
      },
      "source": [
        "missings_train.head(20)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Total</th>\n",
              "      <th>Percent</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>PoolQC</th>\n",
              "      <td>1453</td>\n",
              "      <td>0.995205</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MiscFeature</th>\n",
              "      <td>1406</td>\n",
              "      <td>0.963014</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Alley</th>\n",
              "      <td>1369</td>\n",
              "      <td>0.937671</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Fence</th>\n",
              "      <td>1179</td>\n",
              "      <td>0.807534</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FireplaceQu</th>\n",
              "      <td>690</td>\n",
              "      <td>0.472603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LotFrontage</th>\n",
              "      <td>259</td>\n",
              "      <td>0.177397</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GarageCond</th>\n",
              "      <td>81</td>\n",
              "      <td>0.055479</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GarageType</th>\n",
              "      <td>81</td>\n",
              "      <td>0.055479</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GarageYrBlt</th>\n",
              "      <td>81</td>\n",
              "      <td>0.055479</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GarageFinish</th>\n",
              "      <td>81</td>\n",
              "      <td>0.055479</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GarageQual</th>\n",
              "      <td>81</td>\n",
              "      <td>0.055479</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BsmtExposure</th>\n",
              "      <td>38</td>\n",
              "      <td>0.026027</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BsmtFinType2</th>\n",
              "      <td>38</td>\n",
              "      <td>0.026027</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BsmtFinType1</th>\n",
              "      <td>37</td>\n",
              "      <td>0.025342</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BsmtCond</th>\n",
              "      <td>37</td>\n",
              "      <td>0.025342</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BsmtQual</th>\n",
              "      <td>37</td>\n",
              "      <td>0.025342</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MasVnrArea</th>\n",
              "      <td>8</td>\n",
              "      <td>0.005479</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MasVnrType</th>\n",
              "      <td>8</td>\n",
              "      <td>0.005479</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Electrical</th>\n",
              "      <td>1</td>\n",
              "      <td>0.000685</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Utilities</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              Total   Percent\n",
              "PoolQC         1453  0.995205\n",
              "MiscFeature    1406  0.963014\n",
              "Alley          1369  0.937671\n",
              "Fence          1179  0.807534\n",
              "FireplaceQu     690  0.472603\n",
              "LotFrontage     259  0.177397\n",
              "GarageCond       81  0.055479\n",
              "GarageType       81  0.055479\n",
              "GarageYrBlt      81  0.055479\n",
              "GarageFinish     81  0.055479\n",
              "GarageQual       81  0.055479\n",
              "BsmtExposure     38  0.026027\n",
              "BsmtFinType2     38  0.026027\n",
              "BsmtFinType1     37  0.025342\n",
              "BsmtCond         37  0.025342\n",
              "BsmtQual         37  0.025342\n",
              "MasVnrArea        8  0.005479\n",
              "MasVnrType        8  0.005479\n",
              "Electrical        1  0.000685\n",
              "Utilities         0  0.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "fdqdss0c34u6",
        "colab_type": "code",
        "outputId": "9a373e30-e740-4e7d-ea9b-961a7b106475",
        "colab": {}
      },
      "source": [
        "missings_test.head(20)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Total</th>\n",
              "      <th>Percent</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>PoolQC</th>\n",
              "      <td>1456</td>\n",
              "      <td>0.997944</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MiscFeature</th>\n",
              "      <td>1408</td>\n",
              "      <td>0.965045</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Alley</th>\n",
              "      <td>1352</td>\n",
              "      <td>0.926662</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Fence</th>\n",
              "      <td>1169</td>\n",
              "      <td>0.801234</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FireplaceQu</th>\n",
              "      <td>730</td>\n",
              "      <td>0.500343</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LotFrontage</th>\n",
              "      <td>227</td>\n",
              "      <td>0.155586</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GarageCond</th>\n",
              "      <td>78</td>\n",
              "      <td>0.053461</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GarageQual</th>\n",
              "      <td>78</td>\n",
              "      <td>0.053461</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GarageYrBlt</th>\n",
              "      <td>78</td>\n",
              "      <td>0.053461</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GarageFinish</th>\n",
              "      <td>78</td>\n",
              "      <td>0.053461</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GarageType</th>\n",
              "      <td>76</td>\n",
              "      <td>0.052090</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BsmtCond</th>\n",
              "      <td>45</td>\n",
              "      <td>0.030843</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BsmtQual</th>\n",
              "      <td>44</td>\n",
              "      <td>0.030158</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BsmtExposure</th>\n",
              "      <td>44</td>\n",
              "      <td>0.030158</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BsmtFinType1</th>\n",
              "      <td>42</td>\n",
              "      <td>0.028787</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BsmtFinType2</th>\n",
              "      <td>42</td>\n",
              "      <td>0.028787</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MasVnrType</th>\n",
              "      <td>16</td>\n",
              "      <td>0.010966</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MasVnrArea</th>\n",
              "      <td>15</td>\n",
              "      <td>0.010281</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MSZoning</th>\n",
              "      <td>4</td>\n",
              "      <td>0.002742</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BsmtHalfBath</th>\n",
              "      <td>2</td>\n",
              "      <td>0.001371</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              Total   Percent\n",
              "PoolQC         1456  0.997944\n",
              "MiscFeature    1408  0.965045\n",
              "Alley          1352  0.926662\n",
              "Fence          1169  0.801234\n",
              "FireplaceQu     730  0.500343\n",
              "LotFrontage     227  0.155586\n",
              "GarageCond       78  0.053461\n",
              "GarageQual       78  0.053461\n",
              "GarageYrBlt      78  0.053461\n",
              "GarageFinish     78  0.053461\n",
              "GarageType       76  0.052090\n",
              "BsmtCond         45  0.030843\n",
              "BsmtQual         44  0.030158\n",
              "BsmtExposure     44  0.030158\n",
              "BsmtFinType1     42  0.028787\n",
              "BsmtFinType2     42  0.028787\n",
              "MasVnrType       16  0.010966\n",
              "MasVnrArea       15  0.010281\n",
              "MSZoning          4  0.002742\n",
              "BsmtHalfBath      2  0.001371"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0HIq4h-34vK",
        "colab_type": "text"
      },
      "source": [
        "As a rule of thumb we completely ignore columns that contain at least 15% missing values and will not try to impute the missing values with any kind of computation, e.g. using means. Therefore, we will delete the variables \"PoolQC\", \"MiscFeature\", \"Alley\", \"Fence\", \"FireplaceQu\" and \"LotFrontage\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPYMR1s934vO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = train.drop(columns=[\"PoolQC\", \"MiscFeature\", \"Alley\", \"Fence\", \"FireplaceQu\", \"LotFrontage\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j_eQIwGY34vZ",
        "colab_type": "text"
      },
      "source": [
        "The variables \"GarageCond\", \"GarageType\", \"GarageQual\", \"GarageYrBlt\" and \"GarageFinish\" contain exactly the same number of missing values, which seems kind of odd. Therefore, we'll take a closer look at these variables."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "VnCIfQNl34vd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for var in [\"GarageCond\", \"GarageType\", \"GarageQual\", \"GarageYrBlt\", \"GarageFinish\"]:\n",
        "    print(pd.crosstab(index=train[var], columns=\"count\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CyNYazDC34vu",
        "colab_type": "text"
      },
      "source": [
        "We can see that for \"GarageCond\" and \"GarageQual\" the most frequently occurring value is \"TA\", which means that the condition and quality of the garages are average/typical. We will replace the missing values of these two variables therefore with \"TA\" as well. The variable \"GarageYrBlt\" refers to the year in which the garage was built. Since we also have the year in which the houses themselves are built we can drop this variable without losing much explaining information. In addition to that we also drop the \"GarageFinish\" and \"GarageType\" variable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DRYyQcRR34vy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = train.drop(columns=[\"GarageYrBlt\", \"GarageFinish\", \"GarageType\"])\n",
        "train[\"GarageCond\"] = train.GarageCond.fillna(value=\"TA\")\n",
        "train[\"GarageQual\"] = train.GarageQual.fillna(value=\"TA\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ifXlBAh634v9",
        "colab_type": "text"
      },
      "source": [
        "In the same way as above we take a closer look at the \"Bsmt*\" variables."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "eE6hYxpd34wE",
        "colab_type": "code",
        "outputId": "57ac7ed3-7adc-40dc-fc62-5c8ddf37fee1",
        "colab": {}
      },
      "source": [
        "for var in [\"BsmtFinType2\", \"BsmtExposure\", \"BsmtCond\", \"BsmtFinType1\", \"BsmtQual\"]:\n",
        "    print(pd.crosstab(index=train[var], columns=\"count\"))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "col_0         count\n",
            "BsmtFinType2       \n",
            "ALQ              19\n",
            "BLQ              33\n",
            "GLQ              14\n",
            "LwQ              46\n",
            "Rec              54\n",
            "Unf            1256\n",
            "col_0         count\n",
            "BsmtExposure       \n",
            "Av              221\n",
            "Gd              134\n",
            "Mn              114\n",
            "No              953\n",
            "col_0     count\n",
            "BsmtCond       \n",
            "Fa           45\n",
            "Gd           65\n",
            "Po            2\n",
            "TA         1311\n",
            "col_0         count\n",
            "BsmtFinType1       \n",
            "ALQ             220\n",
            "BLQ             148\n",
            "GLQ             418\n",
            "LwQ              74\n",
            "Rec             133\n",
            "Unf             430\n",
            "col_0     count\n",
            "BsmtQual       \n",
            "Ex          121\n",
            "Fa           35\n",
            "Gd          618\n",
            "TA          649\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HjiroONH34wL",
        "colab_type": "text"
      },
      "source": [
        "We delete the \"BsmtFinType*\" variables since these are highly subjective and do not add much information to our model. The missing values of \"BsmtCond\" will be imputed with the most common value \"TA\". The rows containing missing values for \"BsmtQual\" and \"BsmtExposure\" will be deleted from the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47K32pcX34wO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = train.drop(columns=[\"BsmtFinType1\", \"BsmtFinType2\"])\n",
        "train.BsmtCond = train[\"BsmtCond\"].fillna(value=\"TA\")\n",
        "for var in [\"BsmtQual\", \"BsmtExposure\"]:\n",
        "    train = train.drop(train.loc[train[var].isnull()].index)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aBqT3Xpy34wS",
        "colab_type": "text"
      },
      "source": [
        "The variable \"Electrical\" contains only 1 missing value, therefore we only delete this specific row of data. We proceed in the same way with \"MasVnrType\" and \"MasVnrArea\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywH5kGKi34wV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for var in [\"Electrical\", \"MasVnrType\", \"MasVnrArea\"]:\n",
        "    train = train.drop(train.loc[train[var].isnull()].index)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDFVlGh634wa",
        "colab_type": "text"
      },
      "source": [
        "Running the above code again to check if all missing values are deleted."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vrrDbEEV34wb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "miss_count_train = train.isnull().sum().sort_values(ascending=False)\n",
        "perc_miss_train = (train.isnull().sum()/train.isnull().count()).sort_values(ascending=False)\n",
        "missings_train = pd.concat([miss_count_train, perc_miss_train], axis=1, keys=[\"Total\", \"Percent\"])\n",
        "missings_train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fdaOnbm834wh",
        "colab_type": "text"
      },
      "source": [
        "This looks good.\n",
        "\n",
        "We now handled all the missing data on the training set. As the next step we will clean the test data. Since we want to evaluate our model on Kaggle after finishing the modeling, we cannot drop any observations because we need predicted house prices for each row of the test data. Therefore, we will impute the missing data in the test dataset with the most frequent category for categorical features and the mean for numerical features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T07BcebQ34wi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test = test.drop(columns=[\"PoolQC\", \"MiscFeature\", \"Alley\", \"Fence\", \"FireplaceQu\", \"LotFrontage\"])\n",
        "test = test.drop(columns=[\"GarageYrBlt\", \"GarageFinish\", \"GarageType\"])\n",
        "test[\"GarageCond\"] = test.GarageCond.fillna(value=\"TA\")\n",
        "test[\"GarageQual\"] = test.GarageQual.fillna(value=\"TA\")\n",
        "test = test.drop(columns=[\"BsmtFinType1\", \"BsmtFinType2\"])\n",
        "test.BsmtCond = test[\"BsmtCond\"].fillna(value=\"TA\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9j5QhK034wo",
        "colab_type": "code",
        "outputId": "d182e471-a86e-453c-8a3d-cdced057c8db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "test.shape, train.shape"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1459, 69), (1413, 70))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQ02w-JV34wv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# categorical:\n",
        "for var in [\"BsmtExposure\", \"BsmtQual\", \"MasVnrType\", \"MSZoning\", \"Utilities\", \"Functional\", \"SaleType\", \"Exterior2nd\", \"Exterior1st\", \"KitchenQual\"]:\n",
        "    test[var] = test[var].fillna(value=test[var].value_counts().index[0])\n",
        "\n",
        "# numerical\n",
        "for var in [\"MasVnrArea\", \"BsmtHalfBath\", \"BsmtFullBath\", \"BsmtUnfSF\", \"GarageArea\", \"GarageCars\", \"BsmtFinSF1\", \"BsmtFinSF2\", \"TotalBsmtSF\"]:\n",
        "    test[var] = test[var].fillna(test[var].mean())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tUcKwJKs34wy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "miss_count_test = test.isnull().sum().sort_values(ascending=False)\n",
        "perc_miss_test = (test.isnull().sum() / test.isnull().count()).sort_values(ascending=False)\n",
        "missings_test = pd.concat([miss_count_test, perc_miss_test], axis=1, keys=[\"Total\", \"Percent\"])\n",
        "missings_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R8g62-3534w6",
        "colab_type": "code",
        "outputId": "f4f32a0e-6850-4d9b-f812-d6fefd27aa5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "test.shape, train.shape"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1459, 69), (1413, 70))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BhEJ_0_Z34w_",
        "colab_type": "text"
      },
      "source": [
        "Perfect. We do not have any missing values in our test set anymore and have kept all observations, for which we gonna predict the House Sale Price."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HueY6oIk34xA",
        "colab_type": "text"
      },
      "source": [
        "## Model selection "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eKl7YTLZ34xA",
        "colab_type": "text"
      },
      "source": [
        "We continue by building a Machine Learning Pipeline using Scikit Learn. A pipeline object sequentially applies a list of transformers and a final estimator. \n",
        "\n",
        "\n",
        "We will play around with different algorithms, tune their hyperparameters using Cross Validation and pick the best performing one."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fExfQFwJ34xI",
        "colab_type": "text"
      },
      "source": [
        "Before we can work with our data, we first need to create separate dataframes containing our feature variables and the target variable. This needs to be done only for our training data since it is our aim to predict SalePrice for the test data, which is why it is not contained in this data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h20mFVWB34xK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = train.SalePrice.values\n",
        "X = train.drop(\"SalePrice\", axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FRWuz3DG34xD",
        "colab_type": "text"
      },
      "source": [
        "To make predictions and to fit models, the last step that has to be done is to convert all categorical features into numeric ones. This way scikit-learn can handle them. We do this by using pandas get_dummies() function. To make sure we end up with the same number of columns in both the training and the test dataset we first concatenate both, then apply get_dummies() and then separating them again."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2lF-bISD711G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8ac920c4-1984-46b4-8829-59d812ee2298"
      },
      "source": [
        "X.shape, test.shape\n",
        "type(X), type(test)"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(pandas.core.frame.DataFrame, pandas.core.frame.DataFrame)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gOtj4Mf08Lgl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# creating a dummy to distinguish between train and test data\n",
        "X[\"train\"] = 1\n",
        "test[\"train\"] = 0\n",
        "# concatenating dataframes and creating dummies from categorical features\n",
        "combined = pd.concat([X, test])\n",
        "df = pd.get_dummies(combined, drop_first=True)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZCida-Db94iA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "eb76a3e6-6ce2-4f78-cef2-32a7ce922742"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2872, 214)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MFI0gNK8tNL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = df[df[\"train\"]==1]\n",
        "X = X.drop(\"train\", axis=1)\n",
        "test = df[df[\"train\"]==0]\n",
        "test = test.drop(\"train\", axis=1)\n",
        "X.shape, test.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rbWy5YCa34xN",
        "colab_type": "text"
      },
      "source": [
        "Before training and tuning our models we separate the data into training and test data to evaluate our models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fcheSZ1s34xO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WdjJ2X5B34xR",
        "colab_type": "code",
        "outputId": "6900c6ce-6e92-4a68-8243-e3596d704029",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1130, 213), (283, 213), (1130,), (283,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y34SIsSE34xX",
        "colab_type": "text"
      },
      "source": [
        " ### k-nearest Neighbors (KNN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HeD_xQ7F34xZ",
        "colab_type": "text"
      },
      "source": [
        "We will start with a relatively simple algorithm - k-nearest Neighbor or KNN."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cf2getAk34xa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import preprocessing\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.pipeline import Pipeline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rok4x3bD34xd",
        "colab_type": "text"
      },
      "source": [
        "Looking at the data, we notice that are our feature variables' ranges vary substantially between each other. Therefore we will add a transformer to our pipeline which standardizes the data. Standardization centers each variable around zero with unit variance. This is done by subtracting the means from each feature and dividing by its standard deviation.\n",
        "\n",
        "After that we instantiate our KNN estimator, create a list containing the steps applied by the pipeline and then defining the pipeline."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MU9kzrbr34xe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# instantiate the scaling transformator \n",
        "scaler = preprocessing.StandardScaler()\n",
        "# instantiate the KNN estimator\n",
        "knn = KNeighborsRegressor(n_neighbors=10)\n",
        "# creating a list containing the steps the pipeline is to apply\n",
        "steps_knn =  [(\"scaler\", scaler), (\"knn\", knn)]\n",
        "# define the pipeline object\n",
        "pipeline_knn = Pipeline(steps_knn)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMEhD38F34xk",
        "colab_type": "text"
      },
      "source": [
        "The KNN algorithm has one parameter that can and should be tuned, which is the number of neighbors that should be considered. We will therefore define a dictionary containing all hyperparameters that should be tuned and define the different values that should be tested."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXO70KLy34xl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "neighbors = {\"knn__n_neighbors\":list(range(1,21))}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "er7EuAaD34xo",
        "colab_type": "text"
      },
      "source": [
        "Next we are gonna set up our Cross Validation (CV) object using 5-fold CV and fit it to our data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QPyilhSr34xp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cv_knn = GridSearchCV(pipeline_knn, neighbors, cv=5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98OXx6yB34xt",
        "colab_type": "code",
        "outputId": "dfdd3fcd-0b09-4218-c8cc-ef527a3837a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        }
      },
      "source": [
        "cv_knn.fit(X_train, y_train)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
              "             estimator=Pipeline(memory=None,\n",
              "                                steps=[('scaler',\n",
              "                                        StandardScaler(copy=True,\n",
              "                                                       with_mean=True,\n",
              "                                                       with_std=True)),\n",
              "                                       ('knn',\n",
              "                                        KNeighborsRegressor(algorithm='auto',\n",
              "                                                            leaf_size=30,\n",
              "                                                            metric='minkowski',\n",
              "                                                            metric_params=None,\n",
              "                                                            n_jobs=None,\n",
              "                                                            n_neighbors=10, p=2,\n",
              "                                                            weights='uniform'))],\n",
              "                                verbose=False),\n",
              "             iid='warn', n_jobs=None,\n",
              "             param_grid={'knn__n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11,\n",
              "                                              12, 13, 14, 15, 16, 17, 18, 19,\n",
              "                                              20]},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGoyZJFV34x1",
        "colab_type": "code",
        "outputId": "11474075-a254-418f-b2b2-1dfe451c8872",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "cv_knn.best_params_"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'knn__n_neighbors': 12}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "peS5SY1q34x7",
        "colab_type": "code",
        "outputId": "2a3288e1-924b-4581-e99b-19843172a069",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(cv_knn.refit)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wOJVOIc734yM",
        "colab_type": "text"
      },
      "source": [
        "From the above output we conclude that the default of the argument \"refit\" is True. This means that, by default, our CV pipeline automatically refits the model on the entire training set using the best parameters found by CV, which is 12 in our case. Therefore we can now directly use the CV object to make predictions for unseen data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jzcqAg2-34yO",
        "colab_type": "text"
      },
      "source": [
        "As in the Kaggle challenge we will use the log of the Root mean squared error metric to evaluate our model's performance on the test set. To do this we first need to predict the sales price for the unseen test data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPe4htbc34yP",
        "colab_type": "code",
        "outputId": "03ca664c-533c-4c67-a3e1-06e5b1ca1c16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "y_pred = cv_knn.predict(X_test)\n",
        "rmse_knn = np.sqrt(mean_squared_error(np.log(y_test), np.log(y_pred)))\n",
        "print(\"The KNN algorithm with \" + str(cv_knn.best_params_) + \" yields a (log) RMSE of: \" + str(rmse_knn))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The KNN algorithm with {'knn__n_neighbors': 12} yields a (log) RMSE of: 0.197561198068067\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SskPimED34yV",
        "colab_type": "text"
      },
      "source": [
        "### Random forest"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9cL8LCox34yX",
        "colab_type": "text"
      },
      "source": [
        "After trying out the KNN algorithm, we now continue with the Random Forest Algorithm. Using similar steps as before we will build up a pipeline object applying the transformations and the estimation on our dataset sequentially automatically."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4JrDkEa34ya",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import RandomForestRegressor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6HGS8X334ye",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# instantiate the RandomForest Regressor\n",
        "rf_reg = RandomForestRegressor(random_state=123)\n",
        "# creating a list containing the steps the pipeline should apply\n",
        "steps_rf = [(\"scaler\", scaler), (\"rf_reg\", rf_reg)]\n",
        "# create the pipeline object\n",
        "pipeline_rf = Pipeline(steps_rf)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRW7fCnw34yk",
        "colab_type": "text"
      },
      "source": [
        "For RandomForests there are a large number of Hyperparameters that can be tuned. In this project we are going to tune the number of trees in the random forest [n_estimators], the number of features considered at every split [max_features], the maximum number of levels in a tree [max_depth], the mininum number of samples required to split a node [min_samples_split], the minimum number of observations required at each leaf node [min_samples_leaf] and if bootstrap should be used training each tree [bootstrap]. \n",
        "\n",
        "We first define the ranges for each hyperparameter that should be considered in our CV tuning and then create our search grid containing the before created lists."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qyKm3mWa34yl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_estimators = list(np.arange(200, 2001, 200))\n",
        "max_features = [\"auto\", \"sqrt\", \"log2\"]\n",
        "max_depth = list(np.arange(10, 101, 10))\n",
        "max_depth.append(None)\n",
        "min_samples_split = [2, 5, 10]\n",
        "min_samples_leaf = [1, 2, 4, 8]\n",
        "bootstrap = [True, False]\n",
        "param_dist = {\"rf_reg__n_estimators\": n_estimators,\n",
        "              \"rf_reg__max_features\": max_features,\n",
        "              \"rf_reg__max_depth\": max_depth,\n",
        "              \"rf_reg__min_samples_split\": min_samples_split,\n",
        "              \"rf_reg__min_samples_leaf\": min_samples_leaf,\n",
        "              \"rf_reg__bootstrap\": bootstrap}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_yqnTIW34yo",
        "colab_type": "text"
      },
      "source": [
        "Testing all possible combinations of hyperparameters would ammount to testing $10*3*11*3*3*2 = 5,940$ combinations, instead of testing all of these we will use RandomizedSearchCV to select randomly from our defined distributions which combinations are tested. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fte7QbYB34yp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "cv_random_rf = RandomizedSearchCV(pipeline_rf, param_dist, cv=3, n_iter=100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tAIOPJno34ys",
        "colab_type": "text"
      },
      "source": [
        "Just as before with the KNN algorithm we now can fit the pipeline to our data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYhxe5pi34yv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cv_random_rf.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNCPHI2p34y4",
        "colab_type": "code",
        "outputId": "9b08b524-d3ce-4645-a1a6-fcf7e962e064",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "cv_random_rf.best_params_"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'rf_reg__bootstrap': False,\n",
              " 'rf_reg__max_depth': 80,\n",
              " 'rf_reg__max_features': 'sqrt',\n",
              " 'rf_reg__min_samples_leaf': 1,\n",
              " 'rf_reg__min_samples_split': 2,\n",
              " 'rf_reg__n_estimators': 400}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fu3-4lem34y8",
        "colab_type": "text"
      },
      "source": [
        "Based on the chosen parameters from RandomizedSearchCV we can now manually decrease the range of the hyperparameters to be tested and use GridSearchCV as before to find the best parameters for our model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KtdIgq-KhwYO",
        "colab_type": "code",
        "outputId": "86812bce-f337-40d4-b6cc-d91e92ff50f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "n_estimators_2 = list(np.arange(300, 501, 100))\n",
        "max_depth_2 = list(np.arange(70, 101, 10))\n",
        "max_features_2 = [\"sqrt\"]\n",
        "min_samples_split_2 = [2, 3]\n",
        "min_samples_leaf_2 = [1, 2, 3]\n",
        "bootstrap_2 = [True, False]\n",
        "param_grid = {\"rf_reg__n_estimators\": n_estimators_2,\n",
        "              \"rf_reg__max_features\": max_features_2,\n",
        "              \"rf_reg__max_depth\": max_depth_2,\n",
        "              \"rf_reg__min_samples_split\": min_samples_split_2,\n",
        "              \"rf_reg__min_samples_leaf\": min_samples_leaf_2,\n",
        "              \"rf_reg__bootstrap\": bootstrap_2}\n",
        "param_grid"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'rf_reg__bootstrap': [True, False],\n",
              " 'rf_reg__max_depth': [70, 80, 90, 100],\n",
              " 'rf_reg__max_features': ['sqrt'],\n",
              " 'rf_reg__min_samples_leaf': [1, 2, 3],\n",
              " 'rf_reg__min_samples_split': [2, 3],\n",
              " 'rf_reg__n_estimators': [300, 400, 500]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ktU0qYrcix9e",
        "colab_type": "text"
      },
      "source": [
        "We can now instantiate and then fit our GridSearchCV object as before."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5BxKTAdi3eI",
        "colab_type": "code",
        "outputId": "22903629-6bfc-4d41-852b-d75143c6e634",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        }
      },
      "source": [
        "cv_rf = GridSearchCV(pipeline_rf, param_grid, cv=3)\n",
        "cv_rf.fit(X_train, y_train)"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
              "             estimator=Pipeline(memory=None,\n",
              "                                steps=[('scaler',\n",
              "                                        StandardScaler(copy=True,\n",
              "                                                       with_mean=True,\n",
              "                                                       with_std=True)),\n",
              "                                       ('rf_reg',\n",
              "                                        RandomForestRegressor(bootstrap=True,\n",
              "                                                              criterion='mse',\n",
              "                                                              max_depth=None,\n",
              "                                                              max_features='auto',\n",
              "                                                              max_leaf_nodes=None,\n",
              "                                                              min_impurity_decrease=0.0,\n",
              "                                                              min_impurity_split=None,\n",
              "                                                              min_samples_leaf=1,\n",
              "                                                              min_sampl...\n",
              "                                                              warm_start=False))],\n",
              "                                verbose=False),\n",
              "             iid='warn', n_jobs=None,\n",
              "             param_grid={'rf_reg__bootstrap': [True, False],\n",
              "                         'rf_reg__max_depth': [70, 80, 90, 100],\n",
              "                         'rf_reg__max_features': ['sqrt'],\n",
              "                         'rf_reg__min_samples_leaf': [1, 2, 3],\n",
              "                         'rf_reg__min_samples_split': [2, 3],\n",
              "                         'rf_reg__n_estimators': [300, 400, 500]},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XefWBfX2k7Yf",
        "colab_type": "code",
        "outputId": "19a9a7cd-e5b1-4289-e881-4b12bfde70f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "cv_rf.best_params_, print()"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'rf_reg__bootstrap': False,\n",
              "  'rf_reg__max_depth': 70,\n",
              "  'rf_reg__max_features': 'sqrt',\n",
              "  'rf_reg__min_samples_leaf': 1,\n",
              "  'rf_reg__min_samples_split': 2,\n",
              "  'rf_reg__n_estimators': 400},\n",
              " None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qQJGZHClpNj",
        "colab_type": "code",
        "outputId": "74aa67ba-5027-4c13-ecac-04dbb4f92a86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(cv_rf.refit)"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVISFwxBlS-J",
        "colab_type": "text"
      },
      "source": [
        "We see that the parameters chosen by RandomizedSearchCV were already pretty good and did not really need that much of a finetuning. Furthermore, the GridSearchCV function also already refit the RandomForest model on the whole training data using the parameters that are found to work best.\n",
        "\n",
        "As before, we now can create predictions for our hold out test set and evaluate our model using log RMSE as before."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zk-j57DilnIk",
        "colab_type": "code",
        "outputId": "0ceec008-263c-4b90-ea8d-be8d7700e202",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "y_pred_rf = cv_rf.predict(X_test)\n",
        "rmse_rf = np.sqrt(mean_squared_error(np.log(y_test), np.log(y_pred_rf)))\n",
        "print(\"The RandomForest algorithm with \" + str(cv_rf.best_params_) + \" yields a (log) RMSE of: \" + str(rmse_rf))"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The RandomForest algorithm with {'rf_reg__bootstrap': False, 'rf_reg__max_depth': 70, 'rf_reg__max_features': 'sqrt', 'rf_reg__min_samples_leaf': 1, 'rf_reg__min_samples_split': 2, 'rf_reg__n_estimators': 400} yields a (log) RMSE of: 0.14303960215709952\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2TQLVh4aoXeZ",
        "colab_type": "text"
      },
      "source": [
        "Great! We see a clear improvement in our evaluation metric, i.e. the RandomForest Regressor performs much better than the KNN fitted at first."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZVtZEBkp_PZ",
        "colab_type": "text"
      },
      "source": [
        "### Making predictions and creating our submission file"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkbIguMsqDVO",
        "colab_type": "text"
      },
      "source": [
        "Since we want to check our model's performance in comparison with other people's models, we need to make predictions for the test dataset provided by Kaggle and upload our results to Kaggle. According to the challenge's description, our submission should be a file containing the observation's ID and the predicted SalesPrice. We first create a dataframe and then save it as a .csv file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_a87-KrqEoD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "2604a781-135c-4e6f-8071-2327f16016ce"
      },
      "source": [
        "ident = list(test.Id)\n",
        "print(ident)"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1461, 1462, 1463, 1464, 1465, 1466, 1467, 1468, 1469, 1470, 1471, 1472, 1473, 1474, 1475, 1476, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1485, 1486, 1487, 1488, 1489, 1490, 1491, 1492, 1493, 1494, 1495, 1496, 1497, 1498, 1499, 1500, 1501, 1502, 1503, 1504, 1505, 1506, 1507, 1508, 1509, 1510, 1511, 1512, 1513, 1514, 1515, 1516, 1517, 1518, 1519, 1520, 1521, 1522, 1523, 1524, 1525, 1526, 1527, 1528, 1529, 1530, 1531, 1532, 1533, 1534, 1535, 1536, 1537, 1538, 1539, 1540, 1541, 1542, 1543, 1544, 1545, 1546, 1547, 1548, 1549, 1550, 1551, 1552, 1553, 1554, 1555, 1556, 1557, 1558, 1559, 1560, 1561, 1562, 1563, 1564, 1565, 1566, 1567, 1568, 1569, 1570, 1571, 1572, 1573, 1574, 1575, 1576, 1577, 1578, 1579, 1580, 1581, 1582, 1583, 1584, 1585, 1586, 1587, 1588, 1589, 1590, 1591, 1592, 1593, 1594, 1595, 1596, 1597, 1598, 1599, 1600, 1601, 1602, 1603, 1604, 1605, 1606, 1607, 1608, 1609, 1610, 1611, 1612, 1613, 1614, 1615, 1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1624, 1625, 1626, 1627, 1628, 1629, 1630, 1631, 1632, 1633, 1634, 1635, 1636, 1637, 1638, 1639, 1640, 1641, 1642, 1643, 1644, 1645, 1646, 1647, 1648, 1649, 1650, 1651, 1652, 1653, 1654, 1655, 1656, 1657, 1658, 1659, 1660, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1669, 1670, 1671, 1672, 1673, 1674, 1675, 1676, 1677, 1678, 1679, 1680, 1681, 1682, 1683, 1684, 1685, 1686, 1687, 1688, 1689, 1690, 1691, 1692, 1693, 1694, 1695, 1696, 1697, 1698, 1699, 1700, 1701, 1702, 1703, 1704, 1705, 1706, 1707, 1708, 1709, 1710, 1711, 1712, 1713, 1714, 1715, 1716, 1717, 1718, 1719, 1720, 1721, 1722, 1723, 1724, 1725, 1726, 1727, 1728, 1729, 1730, 1731, 1732, 1733, 1734, 1735, 1736, 1737, 1738, 1739, 1740, 1741, 1742, 1743, 1744, 1745, 1746, 1747, 1748, 1749, 1750, 1751, 1752, 1753, 1754, 1755, 1756, 1757, 1758, 1759, 1760, 1761, 1762, 1763, 1764, 1765, 1766, 1767, 1768, 1769, 1770, 1771, 1772, 1773, 1774, 1775, 1776, 1777, 1778, 1779, 1780, 1781, 1782, 1783, 1784, 1785, 1786, 1787, 1788, 1789, 1790, 1791, 1792, 1793, 1794, 1795, 1796, 1797, 1798, 1799, 1800, 1801, 1802, 1803, 1804, 1805, 1806, 1807, 1808, 1809, 1810, 1811, 1812, 1813, 1814, 1815, 1816, 1817, 1818, 1819, 1820, 1821, 1822, 1823, 1824, 1825, 1826, 1827, 1828, 1829, 1830, 1831, 1832, 1833, 1834, 1835, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1845, 1846, 1847, 1848, 1849, 1850, 1851, 1852, 1853, 1854, 1855, 1856, 1857, 1858, 1859, 1860, 1861, 1862, 1863, 1864, 1865, 1866, 1867, 1868, 1869, 1870, 1871, 1872, 1873, 1874, 1875, 1876, 1877, 1878, 1879, 1880, 1881, 1882, 1883, 1884, 1885, 1886, 1887, 1888, 1889, 1890, 1891, 1892, 1893, 1894, 1895, 1896, 1897, 1898, 1899, 1900, 1901, 1902, 1903, 1904, 1905, 1906, 1907, 1908, 1909, 1910, 1911, 1912, 1913, 1914, 1915, 1916, 1917, 1918, 1919, 1920, 1921, 1922, 1923, 1924, 1925, 1926, 1927, 1928, 1929, 1930, 1931, 1932, 1933, 1934, 1935, 1936, 1937, 1938, 1939, 1940, 1941, 1942, 1943, 1944, 1945, 1946, 1947, 1948, 1949, 1950, 1951, 1952, 1953, 1954, 1955, 1956, 1957, 1958, 1959, 1960, 1961, 1962, 1963, 1964, 1965, 1966, 1967, 1968, 1969, 1970, 1971, 1972, 1973, 1974, 1975, 1976, 1977, 1978, 1979, 1980, 1981, 1982, 1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2024, 2025, 2026, 2027, 2028, 2029, 2030, 2031, 2032, 2033, 2034, 2035, 2036, 2037, 2038, 2039, 2040, 2041, 2042, 2043, 2044, 2045, 2046, 2047, 2048, 2049, 2050, 2051, 2052, 2053, 2054, 2055, 2056, 2057, 2058, 2059, 2060, 2061, 2062, 2063, 2064, 2065, 2066, 2067, 2068, 2069, 2070, 2071, 2072, 2073, 2074, 2075, 2076, 2077, 2078, 2079, 2080, 2081, 2082, 2083, 2084, 2085, 2086, 2087, 2088, 2089, 2090, 2091, 2092, 2093, 2094, 2095, 2096, 2097, 2098, 2099, 2100, 2101, 2102, 2103, 2104, 2105, 2106, 2107, 2108, 2109, 2110, 2111, 2112, 2113, 2114, 2115, 2116, 2117, 2118, 2119, 2120, 2121, 2122, 2123, 2124, 2125, 2126, 2127, 2128, 2129, 2130, 2131, 2132, 2133, 2134, 2135, 2136, 2137, 2138, 2139, 2140, 2141, 2142, 2143, 2144, 2145, 2146, 2147, 2148, 2149, 2150, 2151, 2152, 2153, 2154, 2155, 2156, 2157, 2158, 2159, 2160, 2161, 2162, 2163, 2164, 2165, 2166, 2167, 2168, 2169, 2170, 2171, 2172, 2173, 2174, 2175, 2176, 2177, 2178, 2179, 2180, 2181, 2182, 2183, 2184, 2185, 2186, 2187, 2188, 2189, 2190, 2191, 2192, 2193, 2194, 2195, 2196, 2197, 2198, 2199, 2200, 2201, 2202, 2203, 2204, 2205, 2206, 2207, 2208, 2209, 2210, 2211, 2212, 2213, 2214, 2215, 2216, 2217, 2218, 2219, 2220, 2221, 2222, 2223, 2224, 2225, 2226, 2227, 2228, 2229, 2230, 2231, 2232, 2233, 2234, 2235, 2236, 2237, 2238, 2239, 2240, 2241, 2242, 2243, 2244, 2245, 2246, 2247, 2248, 2249, 2250, 2251, 2252, 2253, 2254, 2255, 2256, 2257, 2258, 2259, 2260, 2261, 2262, 2263, 2264, 2265, 2266, 2267, 2268, 2269, 2270, 2271, 2272, 2273, 2274, 2275, 2276, 2277, 2278, 2279, 2280, 2281, 2282, 2283, 2284, 2285, 2286, 2287, 2288, 2289, 2290, 2291, 2292, 2293, 2294, 2295, 2296, 2297, 2298, 2299, 2300, 2301, 2302, 2303, 2304, 2305, 2306, 2307, 2308, 2309, 2310, 2311, 2312, 2313, 2314, 2315, 2316, 2317, 2318, 2319, 2320, 2321, 2322, 2323, 2324, 2325, 2326, 2327, 2328, 2329, 2330, 2331, 2332, 2333, 2334, 2335, 2336, 2337, 2338, 2339, 2340, 2341, 2342, 2343, 2344, 2345, 2346, 2347, 2348, 2349, 2350, 2351, 2352, 2353, 2354, 2355, 2356, 2357, 2358, 2359, 2360, 2361, 2362, 2363, 2364, 2365, 2366, 2367, 2368, 2369, 2370, 2371, 2372, 2373, 2374, 2375, 2376, 2377, 2378, 2379, 2380, 2381, 2382, 2383, 2384, 2385, 2386, 2387, 2388, 2389, 2390, 2391, 2392, 2393, 2394, 2395, 2396, 2397, 2398, 2399, 2400, 2401, 2402, 2403, 2404, 2405, 2406, 2407, 2408, 2409, 2410, 2411, 2412, 2413, 2414, 2415, 2416, 2417, 2418, 2419, 2420, 2421, 2422, 2423, 2424, 2425, 2426, 2427, 2428, 2429, 2430, 2431, 2432, 2433, 2434, 2435, 2436, 2437, 2438, 2439, 2440, 2441, 2442, 2443, 2444, 2445, 2446, 2447, 2448, 2449, 2450, 2451, 2452, 2453, 2454, 2455, 2456, 2457, 2458, 2459, 2460, 2461, 2462, 2463, 2464, 2465, 2466, 2467, 2468, 2469, 2470, 2471, 2472, 2473, 2474, 2475, 2476, 2477, 2478, 2479, 2480, 2481, 2482, 2483, 2484, 2485, 2486, 2487, 2488, 2489, 2490, 2491, 2492, 2493, 2494, 2495, 2496, 2497, 2498, 2499, 2500, 2501, 2502, 2503, 2504, 2505, 2506, 2507, 2508, 2509, 2510, 2511, 2512, 2513, 2514, 2515, 2516, 2517, 2518, 2519, 2520, 2521, 2522, 2523, 2524, 2525, 2526, 2527, 2528, 2529, 2530, 2531, 2532, 2533, 2534, 2535, 2536, 2537, 2538, 2539, 2540, 2541, 2542, 2543, 2544, 2545, 2546, 2547, 2548, 2549, 2550, 2551, 2552, 2553, 2554, 2555, 2556, 2557, 2558, 2559, 2560, 2561, 2562, 2563, 2564, 2565, 2566, 2567, 2568, 2569, 2570, 2571, 2572, 2573, 2574, 2575, 2576, 2577, 2578, 2579, 2580, 2581, 2582, 2583, 2584, 2585, 2586, 2587, 2588, 2589, 2590, 2591, 2592, 2593, 2594, 2595, 2596, 2597, 2598, 2599, 2600, 2601, 2602, 2603, 2604, 2605, 2606, 2607, 2608, 2609, 2610, 2611, 2612, 2613, 2614, 2615, 2616, 2617, 2618, 2619, 2620, 2621, 2622, 2623, 2624, 2625, 2626, 2627, 2628, 2629, 2630, 2631, 2632, 2633, 2634, 2635, 2636, 2637, 2638, 2639, 2640, 2641, 2642, 2643, 2644, 2645, 2646, 2647, 2648, 2649, 2650, 2651, 2652, 2653, 2654, 2655, 2656, 2657, 2658, 2659, 2660, 2661, 2662, 2663, 2664, 2665, 2666, 2667, 2668, 2669, 2670, 2671, 2672, 2673, 2674, 2675, 2676, 2677, 2678, 2679, 2680, 2681, 2682, 2683, 2684, 2685, 2686, 2687, 2688, 2689, 2690, 2691, 2692, 2693, 2694, 2695, 2696, 2697, 2698, 2699, 2700, 2701, 2702, 2703, 2704, 2705, 2706, 2707, 2708, 2709, 2710, 2711, 2712, 2713, 2714, 2715, 2716, 2717, 2718, 2719, 2720, 2721, 2722, 2723, 2724, 2725, 2726, 2727, 2728, 2729, 2730, 2731, 2732, 2733, 2734, 2735, 2736, 2737, 2738, 2739, 2740, 2741, 2742, 2743, 2744, 2745, 2746, 2747, 2748, 2749, 2750, 2751, 2752, 2753, 2754, 2755, 2756, 2757, 2758, 2759, 2760, 2761, 2762, 2763, 2764, 2765, 2766, 2767, 2768, 2769, 2770, 2771, 2772, 2773, 2774, 2775, 2776, 2777, 2778, 2779, 2780, 2781, 2782, 2783, 2784, 2785, 2786, 2787, 2788, 2789, 2790, 2791, 2792, 2793, 2794, 2795, 2796, 2797, 2798, 2799, 2800, 2801, 2802, 2803, 2804, 2805, 2806, 2807, 2808, 2809, 2810, 2811, 2812, 2813, 2814, 2815, 2816, 2817, 2818, 2819, 2820, 2821, 2822, 2823, 2824, 2825, 2826, 2827, 2828, 2829, 2830, 2831, 2832, 2833, 2834, 2835, 2836, 2837, 2838, 2839, 2840, 2841, 2842, 2843, 2844, 2845, 2846, 2847, 2848, 2849, 2850, 2851, 2852, 2853, 2854, 2855, 2856, 2857, 2858, 2859, 2860, 2861, 2862, 2863, 2864, 2865, 2866, 2867, 2868, 2869, 2870, 2871, 2872, 2873, 2874, 2875, 2876, 2877, 2878, 2879, 2880, 2881, 2882, 2883, 2884, 2885, 2886, 2887, 2888, 2889, 2890, 2891, 2892, 2893, 2894, 2895, 2896, 2897, 2898, 2899, 2900, 2901, 2902, 2903, 2904, 2905, 2906, 2907, 2908, 2909, 2910, 2911, 2912, 2913, 2914, 2915, 2916, 2917, 2918, 2919]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKxXuD-VrJJ0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_pred = list(cv_rf.predict(test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4of08aUhrZj_",
        "colab_type": "code",
        "outputId": "bc251131-36d3-4708-df3e-958ab57c880e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "len(ident), len(test_pred)"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1459, 1459)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZWH2MGgCCHXl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "b5dac6eb-65de-4502-f59c-b600c6674083"
      },
      "source": [
        "submiss = {\"Id\": ident, \"SalePrice\": test_pred}\n",
        "print(submiss)"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'Id': [1461, 1462, 1463, 1464, 1465, 1466, 1467, 1468, 1469, 1470, 1471, 1472, 1473, 1474, 1475, 1476, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1485, 1486, 1487, 1488, 1489, 1490, 1491, 1492, 1493, 1494, 1495, 1496, 1497, 1498, 1499, 1500, 1501, 1502, 1503, 1504, 1505, 1506, 1507, 1508, 1509, 1510, 1511, 1512, 1513, 1514, 1515, 1516, 1517, 1518, 1519, 1520, 1521, 1522, 1523, 1524, 1525, 1526, 1527, 1528, 1529, 1530, 1531, 1532, 1533, 1534, 1535, 1536, 1537, 1538, 1539, 1540, 1541, 1542, 1543, 1544, 1545, 1546, 1547, 1548, 1549, 1550, 1551, 1552, 1553, 1554, 1555, 1556, 1557, 1558, 1559, 1560, 1561, 1562, 1563, 1564, 1565, 1566, 1567, 1568, 1569, 1570, 1571, 1572, 1573, 1574, 1575, 1576, 1577, 1578, 1579, 1580, 1581, 1582, 1583, 1584, 1585, 1586, 1587, 1588, 1589, 1590, 1591, 1592, 1593, 1594, 1595, 1596, 1597, 1598, 1599, 1600, 1601, 1602, 1603, 1604, 1605, 1606, 1607, 1608, 1609, 1610, 1611, 1612, 1613, 1614, 1615, 1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1624, 1625, 1626, 1627, 1628, 1629, 1630, 1631, 1632, 1633, 1634, 1635, 1636, 1637, 1638, 1639, 1640, 1641, 1642, 1643, 1644, 1645, 1646, 1647, 1648, 1649, 1650, 1651, 1652, 1653, 1654, 1655, 1656, 1657, 1658, 1659, 1660, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1669, 1670, 1671, 1672, 1673, 1674, 1675, 1676, 1677, 1678, 1679, 1680, 1681, 1682, 1683, 1684, 1685, 1686, 1687, 1688, 1689, 1690, 1691, 1692, 1693, 1694, 1695, 1696, 1697, 1698, 1699, 1700, 1701, 1702, 1703, 1704, 1705, 1706, 1707, 1708, 1709, 1710, 1711, 1712, 1713, 1714, 1715, 1716, 1717, 1718, 1719, 1720, 1721, 1722, 1723, 1724, 1725, 1726, 1727, 1728, 1729, 1730, 1731, 1732, 1733, 1734, 1735, 1736, 1737, 1738, 1739, 1740, 1741, 1742, 1743, 1744, 1745, 1746, 1747, 1748, 1749, 1750, 1751, 1752, 1753, 1754, 1755, 1756, 1757, 1758, 1759, 1760, 1761, 1762, 1763, 1764, 1765, 1766, 1767, 1768, 1769, 1770, 1771, 1772, 1773, 1774, 1775, 1776, 1777, 1778, 1779, 1780, 1781, 1782, 1783, 1784, 1785, 1786, 1787, 1788, 1789, 1790, 1791, 1792, 1793, 1794, 1795, 1796, 1797, 1798, 1799, 1800, 1801, 1802, 1803, 1804, 1805, 1806, 1807, 1808, 1809, 1810, 1811, 1812, 1813, 1814, 1815, 1816, 1817, 1818, 1819, 1820, 1821, 1822, 1823, 1824, 1825, 1826, 1827, 1828, 1829, 1830, 1831, 1832, 1833, 1834, 1835, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1845, 1846, 1847, 1848, 1849, 1850, 1851, 1852, 1853, 1854, 1855, 1856, 1857, 1858, 1859, 1860, 1861, 1862, 1863, 1864, 1865, 1866, 1867, 1868, 1869, 1870, 1871, 1872, 1873, 1874, 1875, 1876, 1877, 1878, 1879, 1880, 1881, 1882, 1883, 1884, 1885, 1886, 1887, 1888, 1889, 1890, 1891, 1892, 1893, 1894, 1895, 1896, 1897, 1898, 1899, 1900, 1901, 1902, 1903, 1904, 1905, 1906, 1907, 1908, 1909, 1910, 1911, 1912, 1913, 1914, 1915, 1916, 1917, 1918, 1919, 1920, 1921, 1922, 1923, 1924, 1925, 1926, 1927, 1928, 1929, 1930, 1931, 1932, 1933, 1934, 1935, 1936, 1937, 1938, 1939, 1940, 1941, 1942, 1943, 1944, 1945, 1946, 1947, 1948, 1949, 1950, 1951, 1952, 1953, 1954, 1955, 1956, 1957, 1958, 1959, 1960, 1961, 1962, 1963, 1964, 1965, 1966, 1967, 1968, 1969, 1970, 1971, 1972, 1973, 1974, 1975, 1976, 1977, 1978, 1979, 1980, 1981, 1982, 1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2024, 2025, 2026, 2027, 2028, 2029, 2030, 2031, 2032, 2033, 2034, 2035, 2036, 2037, 2038, 2039, 2040, 2041, 2042, 2043, 2044, 2045, 2046, 2047, 2048, 2049, 2050, 2051, 2052, 2053, 2054, 2055, 2056, 2057, 2058, 2059, 2060, 2061, 2062, 2063, 2064, 2065, 2066, 2067, 2068, 2069, 2070, 2071, 2072, 2073, 2074, 2075, 2076, 2077, 2078, 2079, 2080, 2081, 2082, 2083, 2084, 2085, 2086, 2087, 2088, 2089, 2090, 2091, 2092, 2093, 2094, 2095, 2096, 2097, 2098, 2099, 2100, 2101, 2102, 2103, 2104, 2105, 2106, 2107, 2108, 2109, 2110, 2111, 2112, 2113, 2114, 2115, 2116, 2117, 2118, 2119, 2120, 2121, 2122, 2123, 2124, 2125, 2126, 2127, 2128, 2129, 2130, 2131, 2132, 2133, 2134, 2135, 2136, 2137, 2138, 2139, 2140, 2141, 2142, 2143, 2144, 2145, 2146, 2147, 2148, 2149, 2150, 2151, 2152, 2153, 2154, 2155, 2156, 2157, 2158, 2159, 2160, 2161, 2162, 2163, 2164, 2165, 2166, 2167, 2168, 2169, 2170, 2171, 2172, 2173, 2174, 2175, 2176, 2177, 2178, 2179, 2180, 2181, 2182, 2183, 2184, 2185, 2186, 2187, 2188, 2189, 2190, 2191, 2192, 2193, 2194, 2195, 2196, 2197, 2198, 2199, 2200, 2201, 2202, 2203, 2204, 2205, 2206, 2207, 2208, 2209, 2210, 2211, 2212, 2213, 2214, 2215, 2216, 2217, 2218, 2219, 2220, 2221, 2222, 2223, 2224, 2225, 2226, 2227, 2228, 2229, 2230, 2231, 2232, 2233, 2234, 2235, 2236, 2237, 2238, 2239, 2240, 2241, 2242, 2243, 2244, 2245, 2246, 2247, 2248, 2249, 2250, 2251, 2252, 2253, 2254, 2255, 2256, 2257, 2258, 2259, 2260, 2261, 2262, 2263, 2264, 2265, 2266, 2267, 2268, 2269, 2270, 2271, 2272, 2273, 2274, 2275, 2276, 2277, 2278, 2279, 2280, 2281, 2282, 2283, 2284, 2285, 2286, 2287, 2288, 2289, 2290, 2291, 2292, 2293, 2294, 2295, 2296, 2297, 2298, 2299, 2300, 2301, 2302, 2303, 2304, 2305, 2306, 2307, 2308, 2309, 2310, 2311, 2312, 2313, 2314, 2315, 2316, 2317, 2318, 2319, 2320, 2321, 2322, 2323, 2324, 2325, 2326, 2327, 2328, 2329, 2330, 2331, 2332, 2333, 2334, 2335, 2336, 2337, 2338, 2339, 2340, 2341, 2342, 2343, 2344, 2345, 2346, 2347, 2348, 2349, 2350, 2351, 2352, 2353, 2354, 2355, 2356, 2357, 2358, 2359, 2360, 2361, 2362, 2363, 2364, 2365, 2366, 2367, 2368, 2369, 2370, 2371, 2372, 2373, 2374, 2375, 2376, 2377, 2378, 2379, 2380, 2381, 2382, 2383, 2384, 2385, 2386, 2387, 2388, 2389, 2390, 2391, 2392, 2393, 2394, 2395, 2396, 2397, 2398, 2399, 2400, 2401, 2402, 2403, 2404, 2405, 2406, 2407, 2408, 2409, 2410, 2411, 2412, 2413, 2414, 2415, 2416, 2417, 2418, 2419, 2420, 2421, 2422, 2423, 2424, 2425, 2426, 2427, 2428, 2429, 2430, 2431, 2432, 2433, 2434, 2435, 2436, 2437, 2438, 2439, 2440, 2441, 2442, 2443, 2444, 2445, 2446, 2447, 2448, 2449, 2450, 2451, 2452, 2453, 2454, 2455, 2456, 2457, 2458, 2459, 2460, 2461, 2462, 2463, 2464, 2465, 2466, 2467, 2468, 2469, 2470, 2471, 2472, 2473, 2474, 2475, 2476, 2477, 2478, 2479, 2480, 2481, 2482, 2483, 2484, 2485, 2486, 2487, 2488, 2489, 2490, 2491, 2492, 2493, 2494, 2495, 2496, 2497, 2498, 2499, 2500, 2501, 2502, 2503, 2504, 2505, 2506, 2507, 2508, 2509, 2510, 2511, 2512, 2513, 2514, 2515, 2516, 2517, 2518, 2519, 2520, 2521, 2522, 2523, 2524, 2525, 2526, 2527, 2528, 2529, 2530, 2531, 2532, 2533, 2534, 2535, 2536, 2537, 2538, 2539, 2540, 2541, 2542, 2543, 2544, 2545, 2546, 2547, 2548, 2549, 2550, 2551, 2552, 2553, 2554, 2555, 2556, 2557, 2558, 2559, 2560, 2561, 2562, 2563, 2564, 2565, 2566, 2567, 2568, 2569, 2570, 2571, 2572, 2573, 2574, 2575, 2576, 2577, 2578, 2579, 2580, 2581, 2582, 2583, 2584, 2585, 2586, 2587, 2588, 2589, 2590, 2591, 2592, 2593, 2594, 2595, 2596, 2597, 2598, 2599, 2600, 2601, 2602, 2603, 2604, 2605, 2606, 2607, 2608, 2609, 2610, 2611, 2612, 2613, 2614, 2615, 2616, 2617, 2618, 2619, 2620, 2621, 2622, 2623, 2624, 2625, 2626, 2627, 2628, 2629, 2630, 2631, 2632, 2633, 2634, 2635, 2636, 2637, 2638, 2639, 2640, 2641, 2642, 2643, 2644, 2645, 2646, 2647, 2648, 2649, 2650, 2651, 2652, 2653, 2654, 2655, 2656, 2657, 2658, 2659, 2660, 2661, 2662, 2663, 2664, 2665, 2666, 2667, 2668, 2669, 2670, 2671, 2672, 2673, 2674, 2675, 2676, 2677, 2678, 2679, 2680, 2681, 2682, 2683, 2684, 2685, 2686, 2687, 2688, 2689, 2690, 2691, 2692, 2693, 2694, 2695, 2696, 2697, 2698, 2699, 2700, 2701, 2702, 2703, 2704, 2705, 2706, 2707, 2708, 2709, 2710, 2711, 2712, 2713, 2714, 2715, 2716, 2717, 2718, 2719, 2720, 2721, 2722, 2723, 2724, 2725, 2726, 2727, 2728, 2729, 2730, 2731, 2732, 2733, 2734, 2735, 2736, 2737, 2738, 2739, 2740, 2741, 2742, 2743, 2744, 2745, 2746, 2747, 2748, 2749, 2750, 2751, 2752, 2753, 2754, 2755, 2756, 2757, 2758, 2759, 2760, 2761, 2762, 2763, 2764, 2765, 2766, 2767, 2768, 2769, 2770, 2771, 2772, 2773, 2774, 2775, 2776, 2777, 2778, 2779, 2780, 2781, 2782, 2783, 2784, 2785, 2786, 2787, 2788, 2789, 2790, 2791, 2792, 2793, 2794, 2795, 2796, 2797, 2798, 2799, 2800, 2801, 2802, 2803, 2804, 2805, 2806, 2807, 2808, 2809, 2810, 2811, 2812, 2813, 2814, 2815, 2816, 2817, 2818, 2819, 2820, 2821, 2822, 2823, 2824, 2825, 2826, 2827, 2828, 2829, 2830, 2831, 2832, 2833, 2834, 2835, 2836, 2837, 2838, 2839, 2840, 2841, 2842, 2843, 2844, 2845, 2846, 2847, 2848, 2849, 2850, 2851, 2852, 2853, 2854, 2855, 2856, 2857, 2858, 2859, 2860, 2861, 2862, 2863, 2864, 2865, 2866, 2867, 2868, 2869, 2870, 2871, 2872, 2873, 2874, 2875, 2876, 2877, 2878, 2879, 2880, 2881, 2882, 2883, 2884, 2885, 2886, 2887, 2888, 2889, 2890, 2891, 2892, 2893, 2894, 2895, 2896, 2897, 2898, 2899, 2900, 2901, 2902, 2903, 2904, 2905, 2906, 2907, 2908, 2909, 2910, 2911, 2912, 2913, 2914, 2915, 2916, 2917, 2918, 2919], 'SalePrice': [124888.4425, 156320.6625, 180089.4975, 191202.035, 196634.6, 182662.175, 168305.355, 175365.215, 180869.4325, 125526.125, 207157.5175, 95385.815, 94862.25, 153392.085, 121406.1975, 363385.4925, 267040.2175, 292608.54, 295528.0075, 461302.3325, 309748.8575, 204250.7, 181648.415, 175520.575, 179773.96, 204568.505, 329133.03, 233699.4925, 206778.9, 219335.2, 195089.2775, 99513.775, 183069.06, 311715.3375, 290841.59, 235304.8175, 179632.045, 160275.45, 153003.4775, 167266.1875, 175506.9425, 159318.9075, 277085.5325, 231495.985, 214642.4675, 170888.28, 252875.6175, 191374.7025, 157330.0225, 149575.59, 151317.875, 172532.2175, 148087.4525, 167573.1925, 190623.455, 153145.5625, 161152.0125, 136767.1075, 229131.9475, 139574.3125, 143108.665, 162811.17, 118902.54, 126175.265, 127111.6525, 127972.58, 115223.8725, 127633.72, 144273.4675, 167180.24, 143167.8775, 104555.86, 147791.68, 119680.6, 150481.87, 117720.945, 100700.67, 166679.295, 210273.14, 129699.415, 136321.2425, 137761.3225, 180801.5475, 93497.6525, 105864.235, 127479.1425, 139149.2925, 123495.7575, 115504.1, 138052.835, 120701.4525, 145269.9275, 154908.8075, 118718.92, 167823.75, 105567.81, 122756.575, 105369.6475, 122969.43, 142328.3075, 159091.4475, 133202.2275, 124383.835, 164774.5525, 160214.475, 225098.375, 94938.0, 230720.1325, 152317.8875, 144731.69, 130023.46, 141912.75, 245240.1225, 138333.0375, 234810.305, 248219.2975, 197090.1525, 149993.525, 143791.05, 189300.2625, 148636.4425, 125074.375, 322388.5075, 237156.4, 138347.75, 87706.79, 113891.4875, 151518.185, 105870.59, 134181.25, 107408.1725, 136995.31, 119030.6675, 150039.1225, 131679.61, 218012.6925, 173096.3975, 188162.255, 182025.02, 189506.1775, 81570.435, 115696.06, 100370.9825, 279546.6975, 252644.2175, 171672.625, 180172.225, 223743.805, 189728.1175, 167104.555, 150067.3075, 185152.02, 178659.625, 121552.58, 90543.75, 86108.0275, 90395.585, 123903.89, 144861.7775, 182139.135, 143769.9, 140355.865, 279092.93, 225509.495, 127401.64, 170408.6625, 185392.6475, 277320.4425, 174152.2425, 314393.7875, 200605.6525, 239011.4775, 175254.2125, 187329.35, 184668.21, 173654.42, 187616.66, 203073.54, 177445.6825, 235225.19, 175269.93, 225967.6975, 222942.37, 226005.3175, 186767.345, 160956.005, 165899.0875, 141539.415, 141150.925, 125078.46, 123023.975, 95078.0625, 97686.5625, 154496.2675, 142267.11, 146596.0875, 153763.4925, 157951.855, 126748.575, 159412.4225, 402000.9025, 332186.645, 370190.6225, 444223.5275, 306477.715, 331184.525, 341490.63, 328428.5975, 283666.25, 318925.4275, 265085.9725, 433676.76, 307263.4175, 253623.7675, 198249.64, 198285.3675, 215096.7575, 435941.59, 373045.3225, 319612.34, 249314.075, 309880.0075, 190782.7425, 175805.9275, 177863.2275, 168793.5275, 175106.7775, 195244.6225, 195974.04, 187843.0025, 181075.435, 254056.2925, 176483.41, 185806.8625, 173161.0175, 277687.04, 170496.1025, 338761.44, 326474.8325, 248544.2, 262692.9575, 255403.665, 254391.1025, 284296.0675, 236396.975, 415383.7325, 207534.845, 206953.8875, 260934.8875, 227509.7425, 270188.5675, 268788.675, 274538.2875, 213536.0325, 207604.6175, 182137.905, 167666.045, 139268.3375, 210345.9275, 251978.9025, 175575.7125, 132004.295, 165981.4775, 216526.2475, 228558.0075, 197585.0225, 184249.845, 188076.7125, 168036.195, 164326.75, 128536.18, 130912.1725, 120482.55, 127740.26, 138156.645, 124316.4975, 328423.485, 225659.4175, 283641.5025, 231668.1, 204528.6225, 172668.15, 177639.99, 281068.62, 222161.01, 216749.69, 210491.81, 210745.2625, 164898.7525, 144950.945, 221370.74, 122054.7675, 153619.375, 185734.8925, 171917.0625, 130371.515, 119253.15, 151401.315, 162768.5, 165371.2325, 157298.0425, 174923.2, 174189.5125, 122788.6225, 183879.695, 171316.22, 207665.59, 144225.6975, 164628.455, 153234.6825, 133027.225, 143072.975, 143457.57, 156200.3175, 138921.5625, 130168.2125, 115106.165, 141921.0825, 134775.715, 168496.2475, 131622.395, 106232.3625, 147723.95, 114442.0125, 118140.3275, 164676.565, 171283.25, 92004.645, 107533.195, 101120.825, 186603.805, 154784.0, 148059.465, 146848.57, 142054.1225, 141860.2875, 124855.8275, 128081.185, 118715.91, 134736.7625, 130565.6775, 139439.2925, 154002.5, 149160.805, 136567.165, 122202.2325, 136047.7425, 132813.1, 128703.0275, 140836.735, 129086.2975, 109502.105, 119969.1475, 100176.9875, 72919.5625, 105668.2625, 149525.5025, 143971.68, 126647.595, 90124.745, 120623.6225, 154988.9175, 69138.6575, 133405.7025, 138795.015, 112837.625, 109515.6975, 130254.965, 123372.015, 138137.245, 147047.4625, 123229.4625, 141708.795, 136365.1175, 142104.95, 129622.8375, 110718.805, 132788.605, 105802.8925, 173969.4375, 147378.6625, 106596.21, 146205.6875, 139885.28, 146592.285, 155550.19, 168738.7325, 76919.9125, 132968.4325, 128522.8525, 153898.515, 129243.3225, 150931.9225, 172420.7, 177733.655, 216253.5225, 182503.9025, 157401.3425, 143278.935, 162994.1625, 142993.3, 268198.73, 258012.3925, 258012.3925, 331063.2975, 321344.0775, 231143.3975, 292930.4625, 198212.6575, 230252.41, 255416.1175, 175774.755, 229630.9825, 133795.16, 198470.6325, 194054.1, 218075.6, 216926.58, 135454.82, 134806.22, 256406.14, 253070.6975, 202317.27, 219068.055, 242005.28, 288040.3275, 211566.5375, 266423.3325, 173155.3125, 131236.465, 140947.2725, 112276.64, 133365.525, 135874.075, 147259.0825, 122729.71, 129262.54, 121760.7825, 151323.575, 136897.75, 162135.6075, 145702.4675, 188774.4325, 139269.11, 177035.335, 156702.675, 200006.0975, 120480.935, 135120.6375, 124477.035, 188225.5, 266429.1175, 159385.46, 80302.8575, 339482.93, 82965.2375, 253126.3375, 137569.5075, 159646.75, 179356.315, 393454.375, 308059.2475, 199164.7825, 224097.765, 218256.3925, 372514.1225, 140649.145, 163822.3775, 124047.85, 135461.575, 145814.225, 143134.6975, 187822.8625, 180106.325, 179624.6125, 186588.0925, 183795.15, 181522.5775, 239470.075, 194416.4925, 177037.1025, 191609.91, 195463.5025, 328394.285, 366198.455, 161360.7125, 288988.8725, 166458.5925, 228081.855, 182076.025, 253501.04, 224036.61, 184811.95, 188035.9125, 139764.9475, 282181.49, 166427.875, 311472.4225, 150268.4075, 121367.855, 124611.13, 94264.75, 103445.4375, 113667.21, 146317.63, 141555.5375, 300322.0225, 405812.75, 366286.28, 394141.9725, 367049.9775, 345737.1975, 275638.03, 314229.065, 441864.85, 268914.075, 353215.0425, 337087.98, 327063.6725, 201365.46, 334176.285, 238789.465, 226048.1025, 168850.3125, 221671.65, 215250.1875, 187794.2425, 180145.22, 197300.4575, 221927.4775, 218058.1625, 212420.51, 177744.615, 228382.91, 181462.23, 260179.925, 317767.475, 329154.235, 248884.3775, 299560.3475, 285501.5025, 241783.8375, 262691.9875, 291640.56, 223491.3675, 212836.2325, 245084.71, 215299.765, 199036.83, 194792.4775, 144534.445, 180610.4675, 186062.3525, 194988.0275, 202467.7975, 203160.36, 198884.3875, 128700.355, 133778.29, 121393.905, 115770.4925, 173512.0, 151719.69, 257304.78, 339161.0575, 184430.545, 156234.035, 151055.18, 174045.2, 263782.2175, 221366.4925, 232645.19, 245478.4275, 168877.2075, 197804.9775, 179922.9575, 187300.83, 261634.53, 216023.2525, 306133.1875, 251234.1825, 205872.77, 164603.5, 171106.0, 202784.175, 143966.75, 150364.735, 135030.3875, 140437.085, 175047.3075, 118140.9175, 132918.2775, 145966.625, 103976.77, 161477.5875, 145356.725, 129569.2075, 227691.57, 142562.4375, 159573.625, 165307.2175, 135027.4275, 123979.3125, 146322.1875, 128099.12, 165109.5, 143548.9375, 145831.5, 97431.8575, 108691.085, 109859.7625, 143355.72, 139981.4275, 171211.235, 150318.4225, 122073.5625, 149051.11, 128647.91, 130413.4, 121985.075, 124942.21, 138504.0925, 140380.7825, 116304.65, 132896.5125, 127839.575, 123826.4975, 110565.925, 91503.2, 137606.67, 127253.325, 134714.6175, 127600.845, 131580.0525, 142419.585, 92630.6275, 109119.6375, 139382.1725, 74651.515, 125610.6575, 132473.85, 129720.6725, 106403.14, 130162.375, 137935.685, 99684.74, 188880.425, 118794.4525, 117532.4075, 136399.07, 143934.925, 138850.66, 119115.5975, 115046.0275, 145012.18, 117935.115, 141468.755, 124501.9425, 109935.14, 117406.32, 110233.75, 108626.145, 95138.34, 155299.82, 132238.76, 160756.2125, 145835.6875, 139276.7525, 105608.0575, 138285.245, 157142.995, 119740.5, 119275.1875, 125957.7075, 106287.6525, 106596.0425, 126012.88, 145189.9325, 152373.6925, 135101.6875, 146836.625, 137542.365, 146570.175, 143681.895, 132377.6425, 158307.4975, 168592.315, 135580.1475, 151451.14, 199826.875, 115081.545, 175365.6, 161183.865, 115353.4525, 147152.585, 265272.17, 233317.8325, 231434.5325, 200389.6475, 169406.8175, 248576.1325, 405610.51, 348885.77, 263851.965, 193104.7, 142852.53, 210875.835, 207906.7875, 195936.1075, 220997.1425, 153513.635, 144141.8675, 159094.585, 234388.105, 284672.65, 324586.395, 245450.23, 218985.23, 146417.5, 235186.97, 199476.215, 228360.8225, 192594.9725, 134244.25, 142492.55, 148775.445, 144275.0825, 150030.0525, 228894.8675, 110652.185, 114829.26, 103421.88, 109015.4375, 115444.2625, 123366.72, 123155.065, 121793.1325, 148924.5225, 165333.3975, 134055.855, 139894.585, 182854.3125, 159358.6325, 171146.6025, 118891.65, 138013.9825, 198294.9775, 223993.2825, 201525.26, 123114.305, 109580.9275, 112866.0225, 111208.69, 146497.1125, 107395.8875, 142290.6275, 89093.3675, 96252.825, 90954.935, 101123.1025, 348745.8725, 265602.1825, 293532.3925, 230938.065, 153538.08, 204534.9025, 200407.6425, 284064.085, 239535.2975, 164710.425, 233641.22, 183224.6875, 190274.125, 242637.5825, 234883.2125, 267496.755, 342808.4725, 201510.8925, 122136.955, 160711.2, 163851.01, 130150.1775, 128036.375, 97425.1875, 101822.675, 143654.125, 109324.02, 123966.125, 127980.5175, 132663.205, 136298.34, 173283.25, 165578.6575, 179231.1275, 190600.2025, 184213.3575, 202699.2125, 173782.2525, 181063.31, 155896.525, 189416.7725, 208432.4, 338290.84, 405412.6875, 174304.505, 266917.96, 358779.92, 364340.85, 160349.35, 189824.8125, 217345.3675, 210495.5775, 174422.83, 174271.2175, 174444.5925, 184543.71, 180301.91, 149039.1425, 127801.81, 119915.2675, 188146.795, 198529.455, 95977.3025, 114365.165, 137479.7425, 130286.33, 351197.97, 274739.7875, 368089.46, 402903.2275, 332063.82, 399923.82, 434713.3525, 356005.8475, 431834.51, 269452.2325, 314765.9275, 326062.05, 348329.9875, 315468.865, 310460.1525, 250678.5325, 241452.305, 247746.79, 195643.2875, 197071.32, 196271.0275, 228925.905, 264155.94, 237091.77, 199165.5575, 182010.555, 178873.8975, 185382.3175, 173237.94, 206332.62, 180340.575, 183168.805, 178680.7575, 184111.0875, 241678.6125, 172526.15, 185768.165, 174703.65, 207424.59, 174577.32, 213300.035, 220286.62, 182182.95, 178793.265, 340324.285, 349187.685, 307862.9075, 268548.8525, 259640.465, 316717.515, 201138.715, 267735.2175, 229751.305, 377625.225, 219519.065, 231555.255, 218688.1225, 233452.9725, 235563.1525, 209711.9725, 194828.14, 229568.3025, 180560.8925, 289589.43, 250911.5425, 245878.445, 278981.775, 137624.73, 156053.5575, 161153.4025, 201758.5475, 204388.9825, 127502.125, 122131.6825, 136784.125, 257121.44, 140443.1675, 160351.69, 211897.5525, 197229.2225, 227279.8875, 211206.8575, 222863.5175, 173376.3625, 175951.275, 207169.255, 250996.09, 264846.51, 239549.8975, 267525.2375, 318390.015, 150078.815, 192559.035, 150404.02, 168542.4375, 194968.7475, 209163.1125, 236509.8675, 160262.6575, 142361.25, 134781.6425, 132539.8375, 138519.6525, 146033.9525, 138693.9075, 115874.095, 162969.3725, 150433.625, 184577.5475, 149002.645, 201775.095, 127152.165, 92169.485, 80582.3475, 113220.6225, 136965.0825, 136565.85, 154866.5475, 158702.91, 132269.5875, 129951.5625, 139230.45, 138301.7725, 161102.875, 123367.0175, 153952.5525, 135119.8975, 139448.04, 139695.1425, 127966.13, 132014.5175, 127047.27, 133824.7775, 126799.97, 147082.2575, 125115.5925, 137696.7725, 148709.0875, 233256.4175, 136590.37, 146771.455, 164467.94, 119919.98, 132449.9325, 128283.135, 137788.895, 144511.53, 141076.7125, 149400.59, 115840.3225, 110992.3775, 127114.56, 118804.91, 120521.1275, 104474.3525, 106065.97, 124116.6275, 129254.8425, 98134.3425, 139224.7775, 197802.225, 146918.86, 115888.1225, 145133.715, 135412.175, 179069.1775, 106754.0825, 134755.5925, 119800.205, 128763.3125, 122695.2775, 121524.6875, 112126.6275, 132268.63, 120205.96, 130289.2625, 120996.3175, 156004.28, 133275.0175, 121796.275, 142010.9875, 103383.155, 95347.035, 175330.525, 178818.785, 161167.6625, 124779.845, 115299.035, 196013.4575, 115116.0, 130975.58, 164198.605, 120507.18, 166576.29, 135032.3125, 134035.5325, 122898.3075, 132861.52, 129015.2475, 155284.9075, 207882.53, 143961.3075, 155781.57, 154537.77, 106341.615, 189719.9725, 166173.945, 160242.125, 108997.32, 223558.1375, 142123.2725, 119003.2425, 115221.865, 140430.5575, 138681.865, 141140.09, 116300.205, 183917.985, 217112.215, 251707.0775, 311422.1, 252019.405, 223703.46, 224538.0325, 185714.435, 214465.7725, 221419.385, 255718.0175, 150543.2425, 177901.3425, 136185.4775, 138689.585, 230105.295, 214564.3675, 196695.4375, 218993.52, 133990.1775, 147829.66, 149246.2425, 139863.125, 124406.075, 124715.405, 129914.1625, 128244.7575, 248959.6225, 223061.1275, 201375.3875, 236429.73, 284664.265, 234231.6825, 226254.6, 176419.725, 186485.26, 178017.3425, 177287.8125, 177491.86, 137226.4125, 132882.3825, 132785.58, 137451.1925, 134501.68, 163804.445, 163873.5775, 401151.4775, 152203.7725, 125025.5625, 115541.67, 129296.6775, 115768.17, 109273.115, 117975.6825, 161228.005, 138991.555, 132251.3175, 127962.8475, 132778.05, 149077.7575, 178908.0125, 149730.9225, 159300.9425, 132232.0725, 183069.5025, 192592.7775, 123334.72, 206320.7025, 152441.19, 203655.2525, 268321.8875, 126045.5125, 134098.8225, 162142.3825, 94359.1, 88971.7125, 140550.165, 132339.645, 123096.3, 283163.9525, 170646.8825, 203215.775, 214940.805, 194076.0825, 141757.0625, 140475.785, 217007.35, 210579.78, 225404.305, 256294.4625, 177395.525, 204556.36, 331030.745, 204672.1175, 265469.9475, 305837.1525, 176455.8725, 146638.4475, 89043.875, 91384.0625, 90387.885, 88883.055, 158136.3775, 188306.675, 204831.4875, 164670.9225, 115770.365, 141865.19, 155937.24, 128555.125, 123587.1425, 153252.84, 143597.4, 183038.0275, 193806.815, 197640.135, 184746.09, 182637.1575, 189158.4725, 252005.2675, 296212.0475, 298304.435, 168100.2175, 169601.4675, 410704.13, 456814.4125, 354833.65, 438130.4175, 399321.8275, 292609.0975, 382569.76, 153456.225, 184609.7025, 176440.1175, 245251.4125, 183212.705, 159633.8125, 114179.2075, 202913.455, 105948.92, 138509.3825, 97303.6525, 88922.7775, 98276.1975, 138975.4475, 140582.4225, 132937.6, 146854.5175, 403672.8175, 255914.3925, 279896.77, 377786.44, 322285.6175, 300048.2575, 276471.29, 299598.545, 331720.2125, 344703.745, 354014.125, 283110.0075, 258244.3, 305259.405, 280123.5925, 170313.7225, 177931.345, 176887.2175, 283423.0675, 177294.025, 185651.7625, 211855.7975, 209620.365, 173033.4925, 191670.3025, 193544.085, 255090.6675, 277759.205, 284722.2, 356275.6275, 320884.01, 488802.0075, 309590.4425, 321059.5275, 263549.1575, 308437.5125, 225422.1375, 203133.795, 407562.5025, 202791.2625, 139150.82, 202024.735, 136641.69, 196469.8675, 185056.235, 201116.3025, 204437.69, 190482.68, 178405.1525, 166667.59, 124982.2025, 143178.395, 145572.445, 126630.4125, 123745.415, 130075.6425, 135257.79, 112395.4575, 128086.5875, 273644.68, 351828.4175, 178740.895, 147706.8525, 172335.6175, 158259.92, 194021.46, 240169.6525, 160865.99, 163466.8675, 136746.65, 163676.9275, 147875.77, 130378.3025, 135301.125, 148578.0975, 171547.7025, 166180.185, 153106.2475, 143351.0825, 117689.54, 123689.735, 160965.8725, 154727.2525, 136364.3025, 148786.66, 123677.595, 138688.66, 160866.2825, 139071.115, 150819.46, 155208.65, 151061.9675, 148900.85, 138222.7, 129792.5625, 159172.5025, 134552.5025, 134742.1075, 136676.125, 129219.3275, 220358.4925, 150237.8975, 221441.7675, 130721.0025, 108726.8775, 98501.57, 103028.33, 155013.0125, 147513.03, 149035.0, 145232.25, 175350.475, 174154.7975, 234247.0875, 139300.1025, 111438.3075, 138599.2125, 131078.4375, 145733.025, 117693.21, 120092.7825, 173441.8275, 136544.5975, 132091.3125, 131184.93, 139117.4525, 115049.025, 150214.3325, 102644.46, 101461.0625, 106769.5975, 110639.06, 125061.815, 140918.055, 87676.0425, 117950.9275, 94415.36, 156397.785, 111618.7525, 121486.995, 85124.4475, 167743.66, 112663.0275, 121915.365, 105105.015, 182578.78, 122764.32, 121528.1625, 86237.335, 109063.6475, 134023.25, 167035.1525, 149478.225, 105056.7525, 98017.885, 147979.32, 153471.9375, 131974.8675, 133363.005, 162831.155, 153049.425, 174354.35, 157271.5275, 115382.9875, 217718.395, 154938.8225, 138194.83, 169999.5025, 142959.9825, 117596.19, 187628.695, 273435.9625, 179499.1275, 156783.26, 136934.1975, 136969.47, 237040.32, 204481.335, 230676.805, 190281.7375, 255640.075, 292350.1475, 219954.7125, 219005.825, 205153.0175, 169048.5925, 143110.055, 189303.02, 187267.1775, 201704.5975, 226981.01, 149338.505, 164890.79, 122863.3275, 211346.9525, 203318.915, 208008.0875, 211643.825, 277500.48, 225974.0025, 237543.6, 239013.1925, 139680.25, 202264.7925, 209289.525, 186598.755, 201406.585, 144917.26, 128774.7425, 137805.6675, 203225.905, 128590.0375, 242956.8575, 141299.7175, 135314.55, 107889.0925, 123044.57, 130099.6775, 156623.75, 109865.66, 73230.825, 119416.42, 141498.535, 118814.13, 156466.7725, 140109.6725, 168280.0825, 134807.25, 112087.9975, 153246.52, 158940.3025, 178026.3925, 186194.93, 178399.0625, 198171.725, 102464.2175, 121985.8225, 71251.33, 95903.4625, 140346.3375, 79327.42, 114236.3375, 81158.565, 317975.89, 282349.015, 198598.5175, 152619.3925, 223294.37, 159381.81, 195283.16, 195120.8925, 344111.8475, 343758.37, 126369.7675, 201255.7075, 115947.6875, 126308.8675, 149752.6125, 85946.5, 88200.635, 154206.2675, 88557.43, 87026.4125, 89004.0275, 87991.6075, 168285.7375, 115401.235, 225721.265]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ZdkOJp0EqqE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "7ddd7876-5b45-4476-ad19-64d9cf52cf69"
      },
      "source": [
        "submission = pd.DataFrame(submiss)\n",
        "print(submission.head())\n",
        "\"\\n\"\n",
        "\"\\n\"\n",
        "\"\\n\"\n",
        "print(submission.tail())"
      ],
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     Id    SalePrice\n",
            "0  1461  124888.4425\n",
            "1  1462  156320.6625\n",
            "2  1463  180089.4975\n",
            "3  1464  191202.0350\n",
            "4  1465  196634.6000\n",
            "        Id    SalePrice\n",
            "1454  2915   89004.0275\n",
            "1455  2916   87991.6075\n",
            "1456  2917  168285.7375\n",
            "1457  2918  115401.2350\n",
            "1458  2919  225721.2650\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJ5oJxpyFkt-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "submission.to_csv('submission.csv', index=False)\n",
        "# files.download('submission.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wjeEkvJFa8f",
        "colab_type": "text"
      },
      "source": [
        "We can now upload our submission file to Kaggle and check how well our model performs on the unseen test data."
      ]
    }
  ]
}